1、main方法除了作为程序执行的入口这一点比较特殊外，其余和普通的静态方法并无两样，也可以被调用和重载。

2、Java比较器接口升降序的定义

~~~java
public static void testComparator() {
    /**
     * 首先元素的插入顺序固定是先O1后O2，插入时会比较两个元素的权重，大的在后面
     * compare方法返回结果：
     *  1. 大于0，说明第一个元素的权重高，O1在后面
     *  2. 小于0，说明第二个元素的权重高，O2在后面
     *  3. 等于0，说明两个元素权重相同，插入顺序固定
     *
     * 所以升序时compare逻辑为：O1 - O2
     *      假设O1 > O2，则返回值 > 0，说明第一个元素的权重高，也就O2这个小元素要插入到O1前，也就是升序
     * 降序时compare逻辑为：O2 - O1
     *      还是假设O1 > O2，则返回值 < 0，说明第二个元素的权重高，也就O2这个小元素要插入到O1后，也就是降序
     */

    // 升序
    Comparator<Integer> ascComparator = new Comparator<Integer>() {
        @Override
        public int compare(Integer o1, Integer o2) {
            return O1 - O2;
        }
    };

    // 降序
    Comparator<Integer> descComparator = new Comparator<Integer>() {
        @Override
        public int compare(Integer o1, Integer o2) {
            return O2 - O1;
        }
    };
}
~~~



多级dsl查询可以算作一种门面模式，一个结构，路由到多种实现



insmate系统可以整理的技术点

前后端数据格式化逻辑

* 利用泛型方法格式化了API响应体数据结构 **再看看泛型**

  ~~~groovy
  @Slf4j
  final class APIUtils<T> {
      private APIUtils() {
      }
  
      static final <T> APIResp<T> wrapResult(Closure<T> closure) {
          wrapResult(closure, this)
      }
  
      static final <T> APIResp<T> wrapResult(Closure<T> closure, Object delegate) {
          try {
              def result = MyClosureUtils.run(closure).on(delegate).go()
              if (result instanceof MergeResult) {
                  ((MergeResult) result).policy?.calcResult = null
              } else if (result instanceof BindResult) {
                  ((BindResult) result).policy?.calcResult = null
              } else if (result instanceof IssueResult) {
                  ((IssueResult) result).policy?.calcResult = null
              } else if (result instanceof MakePaymentResult) {
                  ((MakePaymentResult) result).policy?.calcResult = null
              } else if (result instanceof CalcResult) {
                  ((CalcResult) result).policy?.calcResult = null
              } else if (result instanceof Policy) {
                  ((Policy) result)?.calcResult = null
              }
              return APIResp.retSuccess(result)
          } catch (BaseException e) {
              return APIResp.retFailure(e)
          }
      }
  }
  ~~~

数据库版本号字段（乐观锁）控制数据的并发更新

数据库使用json字段存储非索引和非审计字段，然后同步数据给es，通过es来实现条件查询

定时任务实现方案，但是要思考下这么在分布式架构下实现定时任务调度

模板配置功能的实现

邮件发送功能

登录用户身份校验

看看有没有什么功能是能用消息中间件去实现的

看下怎么实现了用es统计系统日志的

看下es的索引库是怎么定义和刷新的

es分页查询优化，从scroll改为search after

策略加工厂模式实现可扩展的第三方存储服务









~~~txt
调整batchAdmin用户等基本数据的初始化时机，从基于CommandLineRuner改为基于ApplicationListener<ContextRefreshedEvent>实现，解决项目初始化时可能出现的依赖batchAdmin等数据的ScheduledTask执行失败的问题

* @EnableScheduling引入ScheduledAnnotationBeanPostProcessor，这个Bean后处理器会在Bean初始化后解析其中被@Scheduled标记的方法，将其封装为TriggerTask对象进行调用
* 调用的时机有两个，一个是解析时若发现了自行通过SchedulingConfigurer接口实现类注册的TaskScheduler线程池，就直接通过这个线程池进行调用，若没有找到TaskScheduler，就把TriggerTask对象保持到内部缓存，等待容器发布ContextRefreshedEvent时，基于ScheduledAnnotationBeanPostProcessor自己实现的ApplicationListener接口的onApplicationEvent()，初始化默认的Executors.newSingleThreadScheduledExecutor()，调用缓存的TriggerTask对象
* 这两个调用时间都早于CommandLineRuner，所以可能会出现依赖batchAdmin等数据的ScheduledTask执行时找不到数据的可能性，所以把BacthAdmin这种数据的初始化时机也提早到ContextRefreshedEvent
* 不对，这个其实也没用，因为ContextRefreshedEvent是所以SingletonObjects创建完后才发布，如果自行通过SchedulingConfigurer接口实现类注册了TaskScheduler线程池，在解析@Scheduled就会开始执行了，这个时候ContextRefreshedEvent都还没发布，所以还不如直接在@Scheduled上面指定FixedDelay
~~~





**自我介绍**

各位好，我叫符嘉俊，今年23，21年毕业于湖南工业大学的信息与计算科学专业，目前是三年多的java后端开发经验，熟悉常见Spring系列框架的开发，对部分框架原理也有一定的理解，做过多线程的开发，也有Redis、ElasticSearch等中间件服务的开发经验。在之前的项目工作中也做过和客户的需求沟通，也有一定的需求分析和功能设计经验。

**为什么离职**

本身那边人员流动率就挺高的，导致我在那边基本都是去各种苦大难的项目组赶进度，很多时候还是赶鸭子上架式的临时上手新的业务模块，很少能有个比较安稳的工作阶段，虽然借着这些压力对整个系统的模块都有了一定了解，但我个人其实还是比较倾向于一个平稳的工作环境的，这样也有利于调整我的工作心态和提高效率

**之前的工作中得到什么成长**

技术开发经验的积累，业务梳理能力也得到了提升，在日常工作中也锻炼了沟通能力

**平时怎么学习**

主要是依靠视频网站的教学视频和网络上的技术博客，学习过程中再整理一份自己的笔记

**问面试官**

目前的主营业务是什么？项目的架构设计大概是什么方向？这个岗位的主要开发任务是怎么样的？

**面试问题总结**

* ES的使用心得

  * 使用ES的Dynamic Mappings功能快速初始化索引结构	

  * 优化深度分页查询（查询`top1000~2000`，多节点ES分页时，需要将每个节点的top2000合并后二次排序出`top1000~2000`），改为使用SearchAfter进行分页查询，基于指定的排序值获取下一页数据，这样每个ES节点就只需要返回排序值之后的size条数据给调度节点了，而不用像from size一样每个节点都要返回from+size条数据给调度节点。总的数据量更小，自然效率更高，也避免了OOM

* SpringSession分布式方案

  将session信息存储在Redis中

* Redis+Token实现接口幂等性

  建单页面预先请求后端生成一个Token，后端将Token存在redis，并设置有效期避免过多的资源消耗和防止token泄露长时间无法感知。

  实际发送建单请求时携带Token，后端使用拦截器给自定义注解标注的方法校验token，校验方式是直接去redis删除这个token，删成功了说明token有效

* XSSFWorkBook OOM问题

  从堆栈信息上定位到了XSSFWorkBook OOM问题，基于此问题去网络上了解到XSSFWorkBook会将生成的行数据对象全部放在内存中，数据量过大时自然会出现OOM，然后了解到了SXSSFWorkBook，这个实现只会将新生成的数据存在内存，其余数据都暂存在磁盘之中，以此来避免大数据量的OOM问题

* Redis Set交集操作

  基于redis set类型原生的交集操作，可以快速的获取到用户的共同关注列表

* MySQL SQL优化

  主要是提高sql命中率，发现慢SQL之后，首先分析这个SQL的执行计划，看是否使用了索引（索引定义的是否合适，SQL是否满足最左匹配规则），并尽可能的避免回表查询，如果必须回表，也仅可能的实现索引下推，减少回表次数（通过二级索引如Name去找数据，这时候如果还有Age列的过滤条件，MYSQL会基于Name索引找数据后再去主键索引用Age字段过滤数据，这样就有额外的回表操作，所以最好定义Name和Age的联合索引，联合索引中用Name选中数据后可以直接用Age进行过滤）

* 锁粒度控制

  InnoDB引擎的行锁是针对索引加锁，所以在执行Update语句的时候最好是能利用到索引，不然的话会直接升级为表锁，影响性能

* 系统系能优化

  发现响应速度慢的接口，利用JProfier工具定位耗时最久的方法，优化其执行逻辑，

  1. 如果是数据库查询慢，则尝试优化对应SQL和表的索引定义
  2. 循环Load改为一次性批量查询，并明确好所需字段，尽可能避免select *
  3. 热点资源添加缓存，如数据字典
  4. 热点方法进一步优化

* Redission分布式锁实现原理

  首先是取锁，使用setex或者lua脚本写redis同时设置过期时间保证原子性，取锁之前还都会判断是否已经存在了锁，锁是不是当前客户端占有的，取锁成功后启动一个看门狗后台线程进行自动锁续期，业务完了之后再delete redis数据释放锁。

* Rabbit MQ

  * 消息重复消费怎么控制
    * 消息加唯一性标识
    * 消费者幂等性控制，写数据库的唯一索引或者写Redis，本质就是用锁
    * 手动消息确认，不用自带ack，而是业务完成后手动ack
  * 消息有序性怎么控制
    * 单队列单消费者，天然顺序，但是效率低
    * 还是单队列单消费者，但是消费者收到消息后不直接消费，而是按照业务规则将关键字（业务规则指定等）相同的消息发送到同一个内存队列，每个内存队列由一个线程来处理

* Groovy动态加载脚本的原理

  本质就是**GroovyClassLoader**将指定groovy脚本编译为字节码文件后加载到JVM中，可以动态加载，不用重启服务，Java也是支持动态加载的，比如SpringBoot的热部署

* Select for update一定要在事务中执行吗

  是的，select for update就是加排他锁，而DB锁本身就是为了实现事务的隔离性，自然是要在事务中使用

* treadlocal使用时需要注意什么

  * 注意使用线程池时的清理问题，因为线程池的线程会进行复用，则要考虑在线程执行完任务后清空threadLocalMap，以免数据污染
  * 因为threadLocal作为key存放在线程的threadLocalMap时，key是弱引用，而value是强引用，这样设计的原因如下
    * threadLocal的创建和销毁并不是由当前任务线程管理的，即有可能是将tgreadlocal定位为静态变量，也有可能是开启线程池之前定义的局部变量，所以将threadLocalMap的key定义为弱引用就是为了避免threadlocal自身没有其他引用时一直被任务线程的threadlocalmap所引用，从而导致threadlocal一直无法被回收，出现内存泄漏
    * 而threadlocalmap的value本身就是线程局部变量，其生命周期自然是跟随着任务线程的，所以是强引用，任务线程销毁时，对应threadlocalmap和其中的value自然也被销毁了

* 描述下synchronized关键字的锁升级

  * 无锁状态
  * 偏向锁：一个线程取到锁之后，锁对象的对象头上会记录当前线程自带的锁记录值，锁状态标记为偏向，当前线程再次取锁时可以直接取到
  * 轻量级锁：另一个线程尝试获取锁时，锁对象头状态标记为轻量级锁，采用CAS的方式来竞争锁
  * 重量级锁：轻量级锁CAS竞争失败，升级为重量级锁，锁对象头将指向新生成的monitor对象，线程也将基于Monitor进行竞争，成功线程记为owner，失败线程进入waitset阻塞等待

* ConcorentHashMap是什么实现并发锁的

  * 分段锁：node数据每个元素使用Synchronized作为一个锁
    * CAS：首次生成Node元素时使用CAS而不是Synchronized
